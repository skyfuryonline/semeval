{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8564534",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: wandb in /home/pod/.local/lib/python3.10/site-packages (0.18.7)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/pod/.local/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/pod/.local/lib/python3.10/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.1.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.24.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/pod/.local/lib/python3.10/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/pod/.local/lib/python3.10/site-packages (from wandb) (2.19.0)\n",
      "Requirement already satisfied: setproctitle in /home/pod/.local/lib/python3.10/site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.9.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/pod/.local/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/pod/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: evaluate in /home/pod/.local/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/pod/.local/lib/python3.10/site-packages (from evaluate) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.24.4)\n",
      "Requirement already satisfied: dill in /home/pod/.local/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/pod/.local/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/pod/.local/lib/python3.10/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/pod/.local/lib/python3.10/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/pod/.local/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.12.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/pod/.local/lib/python3.10/site-packages (from evaluate) (0.26.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/pod/.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: peft==0.12.0 in /home/pod/.local/lib/python3.10/site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.12.0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.12.0) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.12.0) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.12.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.12.0) (2.2.0a0+81ea7a4)\n",
      "Requirement already satisfied: transformers in /home/pod/.local/lib/python3.10/site-packages (from peft==0.12.0) (4.46.3)\n",
      "Requirement already satisfied: tqdm in /home/pod/.local/lib/python3.10/site-packages (from peft==0.12.0) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/pod/.local/lib/python3.10/site-packages (from peft==0.12.0) (1.1.1)\n",
      "Requirement already satisfied: safetensors in /home/pod/.local/lib/python3.10/site-packages (from peft==0.12.0) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /home/pod/.local/lib/python3.10/site-packages (from peft==0.12.0) (0.26.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (2023.12.2)\n",
      "Requirement already satisfied: requests in /home/pod/.local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.12.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.12.0) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.12.0) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.12.0) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/pod/.local/lib/python3.10/site-packages (from transformers->peft==0.12.0) (0.20.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.12.0) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.12.0) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: bitsandbytes in /home/pod/.local/lib/python3.10/site-packages (0.44.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.0a0+81ea7a4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.24.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: sacrebleu in /home/pod/.local/lib/python3.10/site-packages (2.4.3)\n",
      "Requirement already satisfied: portalocker in /home/pod/.local/lib/python3.10/site-packages (from sacrebleu) (3.0.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.12.25)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.24.4)\n",
      "Requirement already satisfied: colorama in /home/pod/.local/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /home/pod/.local/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: transformers in /home/pod/.local/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/pod/.local/lib/python3.10/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/pod/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/pod/.local/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/pod/.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/pod/.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: datasets in /home/pod/.local/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/pod/.local/lib/python3.10/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/pod/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/pod/.local/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/pod/.local/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/pod/.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/pod/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2023.12.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/pod/.local/lib/python3.10/site-packages (from datasets) (0.26.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -U wandb\n",
    "! pip install evaluate\n",
    "! pip install peft==0.12.0\n",
    "! pip install -U bitsandbytes\n",
    "! pip install sacrebleu\n",
    "! pip install -U transformers\n",
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233839c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pod/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using the latest cached version of the dataset since fixed_train couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/pod/.cache/huggingface/datasets/fixed_train/default/0.0.0/3a5761256e7f11d5 (last modified on Mon Dec  2 12:14:59 2024).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'source_locale', 'target_locale', 'source', 'target', 'entities', 'from'],\n",
      "        num_rows: 32962\n",
      "    })\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'source_locale', 'target_locale', 'source', 'target', 'entities', 'from'],\n",
      "    num_rows: 29665\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'source_locale', 'target_locale', 'source', 'target', 'entities', 'from'],\n",
      "    num_rows: 3297\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"]=\"https://hf-mirror.com\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, \\\n",
    "    Seq2SeqTrainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import wandb\n",
    "from  datasets import Dataset\n",
    "\n",
    "dataset = load_dataset(\"fixed_train\") \n",
    "\n",
    "print(dataset)\n",
    "# 32962\n",
    "train_val = dataset['train'].train_test_split(test_size=0.1)\n",
    "train_data = train_val['train']\n",
    "print(train_data)\n",
    "# 29665\n",
    "val_data = train_val['test']\n",
    "print(val_data)\n",
    "# 3297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f23a824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to read the token file at /var/run/secrets/kubernetes.io/serviceaccount/token due to permission error ([Errno 13] Permission denied: '/var/run/secrets/kubernetes.io/serviceaccount/token').The current user id is 1000. Consider changing the securityContext to run the container as the current user.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to read the token file at /var/run/secrets/kubernetes.io/serviceaccount/token due to permission error ([Errno 13] Permission denied: '/var/run/secrets/kubernetes.io/serviceaccount/token').The current user id is 1000. Consider changing the securityContext to run the container as the current user.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mskyfurynowonline\u001b[0m (\u001b[33mskyfurynowonline-yunnan-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pod/semeval2025/wandb/run-20241202_122026-197g6u0g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skyfurynowonline-yunnan-university/T5-base/runs/197g6u0g' target=\"_blank\">warm-universe-10</a></strong> to <a href='https://wandb.ai/skyfurynowonline-yunnan-university/T5-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skyfurynowonline-yunnan-university/T5-base' target=\"_blank\">https://wandb.ai/skyfurynowonline-yunnan-university/T5-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skyfurynowonline-yunnan-university/T5-base/runs/197g6u0g' target=\"_blank\">https://wandb.ai/skyfurynowonline-yunnan-university/T5-base/runs/197g6u0g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    os.environ['WANDB_API_KEY'] = \"a464ce6c3b972e3e7090ac20839b9a1daac1b608\"\n",
    "    os.environ[\"WANDB_PROJECT\"] = \"T5-base\"\n",
    "    wandb.init()\n",
    "    \n",
    "    # 尝试移除无用列\n",
    "    column_name = train_data.column_names\n",
    "\n",
    "    model_id = \"google-t5/t5-base\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "#     prefix = '''Given a input sentence from the source language (en) that contains named entities, your task is to accurately translate the named entities in the input sentence to the target language {}: '''\n",
    "    prefix = \"translate English to {}: \"\n",
    "    metric = evaluate.load(\"sacrebleu\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "    # 使用data_collator将数据集中的多个样本合并成一个batch，对齐输入和标签的长度\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer,model=model)\n",
    "    def preprocess_function(examples):\n",
    "#         '''\n",
    "#         在需要处理一个批次样本时，可以通过设置 batched=True，让 map 传入一组样本的批次。\n",
    "#         此时，自定义函数的参数会变成一个包含每列字段的字典，字段的值为一个列表，代表该批次中所有样本在对应列下的数据。\n",
    "#         这样，用户可以灵活选择是否逐条或批量处理数据。\n",
    "#         :param examples:\n",
    "#         :return:\n",
    "#         '''\n",
    "#         inputs = [prefix.format(target_lcoale)+example for example,target_lcoale in zip(examples['source'],examples['target_locale'])]\n",
    "        translate_dict={\n",
    "            \"ar\":\"Arabic\",\n",
    "            \"de\":\"German\",\n",
    "            \"es\":\"Spanish\",\n",
    "            \"fr\":\"French\",\n",
    "            \"it\":\"Italian\",\n",
    "            \"ja\":\"Japanese\",\n",
    "        }\n",
    "        inputs = [prefix.format(translate_dict[target_lcoale])+example for example,target_lcoale in zip(examples['source'],examples['target_locale'])]\n",
    "        \n",
    "        \n",
    "        targets = examples['target']\n",
    "        \n",
    "        \n",
    "#         model_inputs = tokenizer(inputs,text_target=targets,max_length=50,truncation=True,padding=True,return_tensors=\"pt\")\n",
    "\n",
    "        model_inputs = tokenizer(inputs, max_length=64, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
    "        labels = tokenizer(targets, max_length=64, truncation=True, padding=\"max_length\",return_tensors='pt')\n",
    "\n",
    "        # 将目标文本的填充 token 设置为 -100，以便在计算损失时忽略\n",
    "        labels[\"input_ids\"] = [\n",
    "            [l if l != tokenizer.pad_token_id else -100 for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "        # 将编码后的目标设置为模型的标签\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "       \n",
    "        return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d66c5ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'source_locale', 'target_locale', 'source', 'target', 'entities', 'from'],\n",
      "    num_rows: 29665\n",
      "})\n",
      "{'id': '544c02bf', 'source_locale': 'en', 'target_locale': 'fr', 'source': 'Who won the Grammy Award for Best New Artist in 2020?', 'target': 'Qui a remporté le Grammy Award du meilleur nouvel artiste en 2020 ?', 'entities': ['Q1453643'], 'from': 'mintaka'}\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "# 29665\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef93eedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 29665/29665 [00:28<00:00, 1025.50 examples/s]\n",
      "Map: 100%|██████████| 3297/3297 [00:03<00:00, 998.65 examples/s] \n"
     ]
    }
   ],
   "source": [
    "    tokenized_train = train_data.map(preprocess_function,batched=True,remove_columns=column_name)\n",
    "    tokenized_val = val_data.map(preprocess_function,batched=True,remove_columns=column_name)\n",
    "    # 使用一部分进行验证\n",
    "#     tokenized_val_slice = Dataset.from_dict(tokenized_val[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa961c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def postprocess_text(preds, labels):\n",
    "        preds = [pred.strip() for pred in preds]\n",
    "        labels = [[label.strip()] for label in labels]\n",
    "        return preds, labels\n",
    "\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        preds, labels = eval_pred\n",
    "        \n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "            \n",
    "#         print(preds.shape)\n",
    "#         batchsize,seq_len,vocab_size\n",
    "#         (100, 64, 32128)\n",
    "#         input()\n",
    "        \n",
    "        # 将 predictions 从概率转为 token IDs ?\n",
    "        preds = np.argmax(preds,axis=-1) # (batch_size, seq_len)\n",
    "        \n",
    "        # 需要额外处理label吗？\n",
    "        # transformers 中，填充位置通常被标记为 -100，需要将这些位置替换为 tokenizer.pad_token_id，避免在解码时生成错误文本\n",
    "        \n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        \n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "        \n",
    "        result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "        result = {\"bleu\": result[\"score\"]}\n",
    "        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "        result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "        result = {k: round(v, 4) for k, v in result.items()}\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415bc506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pod/.local/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_6166/2795885011.py:33: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5501' max='44499' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5501/44499 29:14 < 3:27:20, 3.13 it/s, Epoch 0.37/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.485600</td>\n",
       "      <td>0.965834</td>\n",
       "      <td>14.085800</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.012400</td>\n",
       "      <td>0.822943</td>\n",
       "      <td>13.186600</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.938900</td>\n",
       "      <td>0.753241</td>\n",
       "      <td>13.362300</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.888800</td>\n",
       "      <td>0.726187</td>\n",
       "      <td>13.006300</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.855300</td>\n",
       "      <td>0.702370</td>\n",
       "      <td>12.777000</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.821700</td>\n",
       "      <td>0.684304</td>\n",
       "      <td>13.405100</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.744600</td>\n",
       "      <td>0.666645</td>\n",
       "      <td>13.029900</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.799200</td>\n",
       "      <td>0.651648</td>\n",
       "      <td>12.769800</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.805200</td>\n",
       "      <td>0.643727</td>\n",
       "      <td>12.675500</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.768200</td>\n",
       "      <td>0.634142</td>\n",
       "      <td>12.715100</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='637' max='1649' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 637/1649 00:32 < 00:51, 19.70 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    # 定义训练的超参数\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir='./semeval-T5base',  # output directory\n",
    "        save_total_limit=3,       # 只保留最近的 3 个检查点\n",
    "#         report_to=\"wandb\",\n",
    "        num_train_epochs=3,  # total number of training epochs\n",
    "        per_device_train_batch_size=2,  # batch size per device during training\n",
    "        per_device_eval_batch_size=2,  # batch size for evaluation\n",
    "        warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,  # strength of weight decay\n",
    "        logging_dir='./logs',  # directory for storing logs\n",
    "        \n",
    "        # 频繁的日志记录可能导致内存增加，特别是当模型需要频繁评估时。\n",
    "        logging_steps=500,\n",
    "        learning_rate=2e-5,  # Set learning rate\n",
    "        evaluation_strategy=\"steps\",\n",
    "        \n",
    "        eval_accumulation_steps=200,\n",
    "        \n",
    "        # 使用T5-base时遇到loss为NAN的问题，或许尝试不使用gradient_checkpointing\n",
    "        # 尝试禁用gradient_checkpointing和FP16，跑出了结果\n",
    "        \n",
    "        # 过多裁剪会导致不能学习到有用的知识\n",
    "#         max_grad_norm=1.0,  # 最大梯度裁剪，防止梯度爆炸\n",
    "        \n",
    "        save_strategy=\"epoch\",\n",
    "        \n",
    "        gradient_checkpointing=True,\n",
    "#         fp16=True, # 开启混合精度\n",
    "        # gradient_accumulation_steps=8,  # 累积 8 个小批次\n",
    "    )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model = model,\n",
    "        args = training_args,\n",
    "        train_dataset = tokenized_train,\n",
    "        eval_dataset = tokenized_val,\n",
    "#         eval_dataset=tokenized_val_slice,\n",
    "        tokenizer = tokenizer,\n",
    "        data_collator = data_collator,\n",
    "        compute_metrics = compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    wandb.finish()\n",
    "    trainer.save_model(\"./my_model_final-T5base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bba98aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  3,  2, 58,  1]], device='cuda:0')\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./my_model_final-T5base\").to(\"cuda\")\n",
    "tokenizerSelf = AutoTokenizer.from_pretrained(\"./my_model_final-T5base\")\n",
    "text =  \"translate English to Japanese: Hello, how are you ? \"\n",
    "inputs = tokenizerSelf(text,return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(inputs['input_ids'],max_length=64,num_beams=5,early_stopping=True)\n",
    "print(outputs)\n",
    "decoded_output = tokenizerSelf.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6d30884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0, 2501,   32,    6,  587,  436,  292,    3,   58,    1]],\n",
      "       device='cuda:0')\n",
      "Hallo, wie sind Sie ?\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id).to(\"cuda\")\n",
    "text = \"translate English to Japanese: Hello, how are you ? \"\n",
    "inputs = tokenizer(text,return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(inputs['input_ids'],max_length=64,num_beams=5,early_stopping=True)\n",
    "print(outputs)\n",
    "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e976a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
