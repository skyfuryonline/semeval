{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15865ec5-4edd-4dd2-8173-b856f8f1c187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting wandb\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/45/e0/7ba3b78a74413b7467300cb7a5d486b9871ee464a7cade98ea869d3ca3df/wandb-0.19.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (6.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/31/4d/74597bb6bcc23abc774b8901277652c61331a9d4d0a8d1bdb20679b9bbcb/sentry_sdk-2.19.2-py2.py3-none-any.whl (322 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/44/bf/a447a51054ceed23f69d4f7370289044b4508569f11da6db2eec087bc174/setproctitle-1.3.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from wandb) (72.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.11/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=2.6->wandb) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Installing collected packages: setproctitle, sentry-sdk, docker-pycreds, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 sentry-sdk-2.19.2 setproctitle-1.3.4 wandb-0.19.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting evaluate\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a2/e7/cbca9e2d2590eb9b5aa8f7ebabe1beb1498f9462d2ecede5c9fd9735faaf/evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Collecting datasets>=2.0.0 (from evaluate)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/ed/a5/33cf000137545a08b0a3a6ea76c8ccbd87917f78bb5d737f9f56f3b11ef6/datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.0.1)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from evaluate) (4.66.5)\n",
      "Collecting xxhash (from evaluate)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d9/72/9256303f10e41ab004799a4aa74b80b3c5977d6383ae4550548b24bd1971/xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/b2/07/8cbb75d6cfbe8712d8f7f6a5615f083c6e710ab916b748fbb20373ddb142/multiprocess-0.70.17-py311-none-any.whl (144 kB)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
      "Collecting huggingface-hub>=0.7.0 (from evaluate)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/44/5a/dc6af87c61f89b23439eb95521e4e99862636cfd538ae12fd36be5483e5f/huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate) (24.1)\n",
      "Collecting filelock (from datasets>=2.0.0->evaluate)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/b9/f8/feced7779d755758a52d1f6635d990b8d98dc0a29fa568bbe0625f18fdf3/filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/50/15/b56e50e8debaf439f44befec5b2af11db85f6e0f344c3113ae0be0593a91/multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Collecting aiohttp (from datasets>=2.0.0->evaluate)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/7c/b8/df6d76a149cbd969a58da478baec0be617287c496c842ddf21fe6bce07b3/aiohttp-3.11.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2024.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/b9/74/fbb6559de3607b3300b9be3cc64e97548d55678e44623db17820dbd20002/aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/b8/5f/c10123e8d64867bc9b4f2f510a32042a306ff5fcd7e2e09e5ae5100ee333/frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/ba/af/73d13b918071ff9b2205fcf773d316e0f8fefb4ec65354bbcf0b10908cc6/multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/85/14/01fe53580a8e1734ebb704a3482b7829a0ef4ea68d356141cf0994d9659b/propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/af/ba/1865d85212351ad160f19fb99808acf23aab9a0f8ff31c8c9f1b4d671fc9/yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: xxhash, propcache, multiprocess, multidict, frozenlist, filelock, aiohappyeyeballs, yarl, huggingface-hub, aiosignal, aiohttp, datasets, evaluate\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.1 datasets-3.1.0 evaluate-0.4.3 filelock-3.16.1 frozenlist-1.5.0 huggingface-hub-0.26.5 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.1 xxhash-3.5.0 yarl-1.18.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting peft==0.12.0\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/62/72/fcabddf222ec938c3cbd5616e5a72796938b5235897e07a1fcc2a8e7735e/peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from peft==0.12.0) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from peft==0.12.0) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft==0.12.0) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from peft==0.12.0) (6.0.2)\n",
      "Collecting torch>=1.13.0 (from peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d1/35/e8b2daf02ce933e4518e6f5682c72fd0ed66c15910ea1fb4168f442b71c4/torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting transformers (from peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d0/a7/7eedcf6a359e1e1eff3bc204ad022485aa5d88c08e1e3e0e0aee8a2e2235/transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft==0.12.0) (4.66.5)\n",
      "Collecting accelerate>=0.21.0 (from peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/7b/92/e3f810d0910a71979fe7341803e187cbf85e2b50146c8aa3796eb7bc51b4/accelerate-1.2.0-py3-none-any.whl (336 kB)\n",
      "Collecting safetensors (from peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/e6/ee/69e498a892f208bd1da4104d4b9be887f8611bf4942144718b6738482250/safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.11/site-packages (from peft==0.12.0) (0.26.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.12.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.12.0) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/2c/14/91ae57cd4db3f9ef7aa99f4019cfa8d54cb4caa7e00975df6467e9725a9f/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/ea/27/1795d86fe88ef397885f2e580ac37628ed058a92ed2c39dc8eac3adf0619/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/67/42/f4f60238e8194a3106d06a058d494b18e006c10bb2b915655bd9f6ea4cb1/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/9f/fd/713452cd72343f682b1c7b9321e23829f00b842ceaedcda96e742ea0b0b3/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/ae/71/1c91302526c45ab494c23f61c7a84aa568b8c1f9d196efa5993957faf906/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/27/94/3266821f65b92b3138631e9c8e7fe1fb513804ac934485a8d05776e1dd43/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/8a/6d/44ad094874c6f1b9c654f8ed939590bdc408349f137f9b98a3a23ccec411/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3a/e1/5b9089a4b2a4790dfdea8b3a006052cfecff58139d5a4e34cb1a51df8d6f/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/db/f7/97a9ea26ed4bbbfc2d470994b8b4f338ef663be97b8f677519ac195e113d/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/df/99/12cd266d6233f47d00daf3a72739872bdc10267d0383508b0b9c84a18bb6/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/87/20/199b8713428322a2f22b722c62b8cc278cc53dffa9705d744484b5035ee9/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/ff/ff/847841bacfbefc97a00036e0fce5a0f086b640756dc38caea5e1bb002655/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.1.0 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/86/17/d9a5cf4fcf46291856d1e90762e36cbabd2a56c7265da0d1d9508c8e3943/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy==1.13.1 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/b2/fe/81695a1aa331a842b582453b605175f419fe8540355886031328089d840a/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.12.0) (1.3.0)\n",
      "Collecting regex!=2019.12.17 (from transformers->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/bf/ce/0d0e61429f603bac433910d99ef1a02ce45a8967ffbe3cbee48599e62d88/regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.22,>=0.21 (from transformers->peft==0.12.0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/22/06/69d7ce374747edaf1695a4f61b83570d91cc8bbfc51ccfecf76f56ab4aac/tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft==0.12.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (2024.7.4)\n",
      "Installing collected packages: triton, sympy, safetensors, regex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, torch, accelerate, peft\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed accelerate-1.2.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 peft-0.12.0 regex-2024.11.6 safetensors-0.4.5 sympy-1.13.1 tokenizers-0.21.0 torch-2.5.1 transformers-4.47.0 triton-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting bitsandbytes\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/99/9a/f41d252bf8b0bc5969b4dce1274cd04b7ddc541de1060dd27eca680bc1b2/bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (2.5.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (2.0.1)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (3.16.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting sacrebleu\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/15/d8/e51d35bc863caa19ddeae48dfb890581a19326973ad1c9fa5dcfc63310f7/sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3d/4c/4cb6bb4061910ac74c444be76e7d17dba97d9057030cca2f96947c3f7a0f/portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (2024.11.6)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (2.0.1)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (0.4.6)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/42/07/b29571a58a3a80681722ea8ed0ba569211d9bb8531ad49b5cacf6d409185/lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tabulate, portalocker, lxml, sacrebleu\n",
      "Successfully installed lxml-5.3.0 portalocker-3.0.0 sacrebleu-2.4.3 tabulate-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.0.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.26.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting rouge_score\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/e2/c5/9136736c37022a6ad27fea38f3111eb8f02fe75d067f9a985cc358653102/rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting absl-py (from rouge_score)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting nltk (from rouge_score)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from rouge_score) (2.0.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.11/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk->rouge_score) (4.66.5)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=0389edb257775b5e9a51cfb169892523453058841c2dd1ebb403a1c897634025\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ix96s90a/wheels/67/13/5c/44cae0fa734b47697235e96ab977556ed96599f5e7acd0bf18\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: nltk, absl-py, rouge_score\n",
      "Successfully installed absl-py-2.1.0 nltk-3.9.1 rouge_score-0.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -U wandb -i https://mirrors.aliyun.com/pypi/simple/\n",
    "! pip install evaluate -i https://mirrors.aliyun.com/pypi/simple/\n",
    "! pip install peft==0.12.0 -i https://mirrors.aliyun.com/pypi/simple/\n",
    "! pip install -U bitsandbytes -i https://mirrors.aliyun.com/pypi/simple/\n",
    "! pip install sacrebleu -i https://mirrors.aliyun.com/pypi/simple/\n",
    "! pip install -U transformers -i https://mirrors.aliyun.com/pypi/simple/\n",
    "! pip install datasets -i https://mirrors.aliyun.com/pypi/simple/\n",
    "! pip install rouge_score -i https://mirrors.aliyun.com/pypi/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d01b7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85158cf136b43adaf6098b27d2085f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/31.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0511707391423a8939f10d14eae30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fixed_train.zip:   0%|          | 0.00/1.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5fc28d11b9480aaeb99f957906fdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'source_locale', 'target_locale', 'source', 'target', 'entities', 'from'],\n",
      "        num_rows: 32962\n",
      "    })\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'source_locale', 'target_locale', 'source', 'target', 'entities', 'from'],\n",
      "    num_rows: 29665\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'source_locale', 'target_locale', 'source', 'target', 'entities', 'from'],\n",
      "    num_rows: 3297\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"]=\"https://hf-mirror.com\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, \\\n",
    "    Seq2SeqTrainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import wandb \n",
    "from  datasets import Dataset\n",
    "\n",
    "dataset = load_dataset(\"skyfuryLH/semeval2025\") \n",
    "\n",
    "print(dataset)\n",
    "# 32962\n",
    "train_val = dataset['train'].train_test_split(test_size=0.1)\n",
    "train_data = train_val['train']\n",
    "print(train_data)\n",
    "# 29665\n",
    "val_data = train_val['test']\n",
    "print(val_data)\n",
    "# 3297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b627731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mskyfurynowonline\u001b[0m (\u001b[33mskyfurynowonline-yunnan-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54bbe94653943258d90890f340618d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112921281407277, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/home/haosuan15887127936/test-t5/semeval-T5large/wandb/run-20241207_002910-pufro722</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skyfurynowonline-yunnan-university/T5-large-on-full-with-rouge-bleu/runs/pufro722' target=\"_blank\">logical-monkey-11</a></strong> to <a href='https://wandb.ai/skyfurynowonline-yunnan-university/T5-large-on-full-with-rouge-bleu' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skyfurynowonline-yunnan-university/T5-large-on-full-with-rouge-bleu' target=\"_blank\">https://wandb.ai/skyfurynowonline-yunnan-university/T5-large-on-full-with-rouge-bleu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skyfurynowonline-yunnan-university/T5-large-on-full-with-rouge-bleu/runs/pufro722' target=\"_blank\">https://wandb.ai/skyfurynowonline-yunnan-university/T5-large-on-full-with-rouge-bleu/runs/pufro722</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc49858e81ce41a1ba68efbbe46b9703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11f3bde8e704bfdaa2cae9f8514f685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28babc0fad2a4bffb2b1407d6ab9fc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1f86c15cd548abb24e5ae84fef73c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe251a6a13f4f01a07d351b2fa406df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7c00361c474e8c842e95d43b07da9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66644a1664c64f8fb3d432753561a610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    os.environ['WANDB_API_KEY'] = \"a464ce6c3b972e3e7090ac20839b9a1daac1b608\"\n",
    "    os.environ[\"WANDB_PROJECT\"] = \"T5-large-on-full-with-rouge-bleu\"\n",
    "    wandb.init()\n",
    "    \n",
    "    # 尝试移除无用列\n",
    "    column_name = train_data.column_names\n",
    "\n",
    "    model_id = \"google-t5/t5-large\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "#     prefix = '''Given a input sentence from the source language (en) that contains named entities, your task is to accurately translate the named entities in the input sentence to the target language {}: '''\n",
    "    prefix = \"translate English to {}: \"\n",
    "    # metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "    bleuM = evaluate.load(\"sacrebleu\")\n",
    "    rougeM = evaluate.load(\"rouge\")\n",
    "\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "    # 使用data_collator将数据集中的多个样本合并成一个batch，对齐输入和标签的长度\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer,model=model)\n",
    "    def preprocess_function(examples):\n",
    "#         '''\n",
    "#         在需要处理一个批次样本时，可以通过设置 batched=True，让 map 传入一组样本的批次。\n",
    "#         此时，自定义函数的参数会变成一个包含每列字段的字典，字段的值为一个列表，代表该批次中所有样本在对应列下的数据。\n",
    "#         这样，用户可以灵活选择是否逐条或批量处理数据。\n",
    "#         :param examples:\n",
    "#         :return:\n",
    "#         '''\n",
    "#         inputs = [prefix.format(target_lcoale)+example for example,target_lcoale in zip(examples['source'],examples['target_locale'])]\n",
    "        translate_dict={\n",
    "            \"ar\":\"Arabic\",\n",
    "            \"de\":\"German\",\n",
    "            \"es\":\"Spanish\",\n",
    "            \"fr\":\"French\",\n",
    "            \"it\":\"Italian\",\n",
    "            \"ja\":\"Japanese\",\n",
    "        }\n",
    "        inputs = [prefix.format(translate_dict[target_lcoale])+example for example,target_lcoale in zip(examples['source'],examples['target_locale'])]\n",
    "        \n",
    "        \n",
    "        targets = examples['target']\n",
    "        \n",
    "        \n",
    "#         model_inputs = tokenizer(inputs,text_target=targets,max_length=50,truncation=True,padding=True,return_tensors=\"pt\")\n",
    "\n",
    "        model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
    "        labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\",return_tensors='pt')\n",
    "\n",
    "        # 将目标文本的填充 token 设置为 -100，以便在计算损失时忽略\n",
    "        labels[\"input_ids\"] = [\n",
    "            [l if l != tokenizer.pad_token_id else -100 for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "        # 将编码后的目标设置为模型的标签\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "       \n",
    "        return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f7b1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'source_locale', 'target_locale', 'source', 'target', 'entities', 'from'],\n",
      "    num_rows: 29665\n",
      "})\n",
      "{'id': '7655b908', 'source_locale': 'en', 'target_locale': 'es', 'source': 'Who is older, Jay-Z or Eminem?', 'target': '¿Quién es mayor: Jay Z o Eminem?', 'entities': ['Q62766'], 'from': 'mintaka'}\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "# 29665\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fec472c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ccd2d76e9141398d8eded945246326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29665 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfef44692174fc0abadc0ff53de7d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3297 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    tokenized_train = train_data.map(preprocess_function,batched=True,remove_columns=column_name)\n",
    "    tokenized_val = val_data.map(preprocess_function,batched=True,remove_columns=column_name)\n",
    "    # 使用一部分进行验证\n",
    "#     tokenized_val_slice = Dataset.from_dict(tokenized_val[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65081984",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def postprocess_text(preds, labels):\n",
    "        preds = [pred.strip() for pred in preds]\n",
    "        labels = [[label.strip()] for label in labels]\n",
    "        return preds, labels\n",
    "\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        preds, labels = eval_pred\n",
    "        \n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "            \n",
    "#         print(preds.shape)\n",
    "#         batchsize,seq_len,vocab_size\n",
    "#         (100, 64, 32128)\n",
    "#         input()\n",
    "        \n",
    "        # 将 predictions 从概率转为 token IDs ?\n",
    "        preds = np.argmax(preds,axis=-1) # (batch_size, seq_len)\n",
    "        \n",
    "        # 需要额外处理label吗？\n",
    "        # transformers 中，填充位置通常被标记为 -100，需要将这些位置替换为 tokenizer.pad_token_id，避免在解码时生成错误文本\n",
    "        \n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        \n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "        \n",
    "        result = rougeM.compute(predictions=decoded_preds,references=decoded_labels)\n",
    "        reuslt_bleu = bleuM.compute(predictions=decoded_preds,references=decoded_labels)\n",
    "        result['bleu'] = reuslt_bleu['score']\n",
    "\n",
    "        # result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "        # result = {\"bleu\": result[\"score\"]}\n",
    "        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "        result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "        \n",
    "        # result = {k: round(v, 4) for k, v in result.items()}\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a1bbd1-1e54-43b3-82da-16a60c047bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_165/434171784.py:33: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11127' max='11127' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11127/11127 2:34:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>0.613990</td>\n",
       "      <td>0.191515</td>\n",
       "      <td>0.118674</td>\n",
       "      <td>0.188570</td>\n",
       "      <td>0.188710</td>\n",
       "      <td>6.490792</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.662300</td>\n",
       "      <td>0.542412</td>\n",
       "      <td>0.193140</td>\n",
       "      <td>0.121609</td>\n",
       "      <td>0.190985</td>\n",
       "      <td>0.191261</td>\n",
       "      <td>6.133454</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.598500</td>\n",
       "      <td>0.517829</td>\n",
       "      <td>0.193054</td>\n",
       "      <td>0.126085</td>\n",
       "      <td>0.191178</td>\n",
       "      <td>0.191453</td>\n",
       "      <td>6.250336</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.601600</td>\n",
       "      <td>0.493582</td>\n",
       "      <td>0.205978</td>\n",
       "      <td>0.131281</td>\n",
       "      <td>0.204041</td>\n",
       "      <td>0.204282</td>\n",
       "      <td>6.449366</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.561000</td>\n",
       "      <td>0.477391</td>\n",
       "      <td>0.207823</td>\n",
       "      <td>0.134393</td>\n",
       "      <td>0.205749</td>\n",
       "      <td>0.206152</td>\n",
       "      <td>6.475122</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.543700</td>\n",
       "      <td>0.468769</td>\n",
       "      <td>0.210630</td>\n",
       "      <td>0.135224</td>\n",
       "      <td>0.209009</td>\n",
       "      <td>0.209308</td>\n",
       "      <td>6.313608</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.528700</td>\n",
       "      <td>0.458636</td>\n",
       "      <td>0.210997</td>\n",
       "      <td>0.138074</td>\n",
       "      <td>0.209311</td>\n",
       "      <td>0.209538</td>\n",
       "      <td>6.516031</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>0.451491</td>\n",
       "      <td>0.216889</td>\n",
       "      <td>0.139020</td>\n",
       "      <td>0.215129</td>\n",
       "      <td>0.215495</td>\n",
       "      <td>6.603856</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.475200</td>\n",
       "      <td>0.444742</td>\n",
       "      <td>0.216403</td>\n",
       "      <td>0.141972</td>\n",
       "      <td>0.214570</td>\n",
       "      <td>0.214956</td>\n",
       "      <td>6.636997</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>0.442683</td>\n",
       "      <td>0.215596</td>\n",
       "      <td>0.142364</td>\n",
       "      <td>0.213770</td>\n",
       "      <td>0.214165</td>\n",
       "      <td>6.624335</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.463800</td>\n",
       "      <td>0.437132</td>\n",
       "      <td>0.218796</td>\n",
       "      <td>0.143437</td>\n",
       "      <td>0.217073</td>\n",
       "      <td>0.217238</td>\n",
       "      <td>6.687362</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.459500</td>\n",
       "      <td>0.429894</td>\n",
       "      <td>0.217890</td>\n",
       "      <td>0.145071</td>\n",
       "      <td>0.216344</td>\n",
       "      <td>0.216785</td>\n",
       "      <td>6.811596</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.427368</td>\n",
       "      <td>0.221195</td>\n",
       "      <td>0.143910</td>\n",
       "      <td>0.219491</td>\n",
       "      <td>0.219768</td>\n",
       "      <td>6.840599</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.446700</td>\n",
       "      <td>0.423495</td>\n",
       "      <td>0.220762</td>\n",
       "      <td>0.145118</td>\n",
       "      <td>0.218428</td>\n",
       "      <td>0.219075</td>\n",
       "      <td>6.749783</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.452300</td>\n",
       "      <td>0.420581</td>\n",
       "      <td>0.214025</td>\n",
       "      <td>0.144429</td>\n",
       "      <td>0.212096</td>\n",
       "      <td>0.212386</td>\n",
       "      <td>6.764509</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.405700</td>\n",
       "      <td>0.420900</td>\n",
       "      <td>0.222817</td>\n",
       "      <td>0.145649</td>\n",
       "      <td>0.220632</td>\n",
       "      <td>0.221100</td>\n",
       "      <td>6.848956</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.419489</td>\n",
       "      <td>0.221203</td>\n",
       "      <td>0.145273</td>\n",
       "      <td>0.219416</td>\n",
       "      <td>0.219683</td>\n",
       "      <td>6.772169</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.412900</td>\n",
       "      <td>0.419093</td>\n",
       "      <td>0.221822</td>\n",
       "      <td>0.145891</td>\n",
       "      <td>0.219878</td>\n",
       "      <td>0.220333</td>\n",
       "      <td>6.759696</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.420900</td>\n",
       "      <td>0.417094</td>\n",
       "      <td>0.221943</td>\n",
       "      <td>0.145922</td>\n",
       "      <td>0.220095</td>\n",
       "      <td>0.220596</td>\n",
       "      <td>6.803091</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.412800</td>\n",
       "      <td>0.416506</td>\n",
       "      <td>0.223425</td>\n",
       "      <td>0.146894</td>\n",
       "      <td>0.221680</td>\n",
       "      <td>0.222058</td>\n",
       "      <td>6.865635</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.403700</td>\n",
       "      <td>0.416629</td>\n",
       "      <td>0.225929</td>\n",
       "      <td>0.147134</td>\n",
       "      <td>0.224275</td>\n",
       "      <td>0.224591</td>\n",
       "      <td>6.897778</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.419100</td>\n",
       "      <td>0.415915</td>\n",
       "      <td>0.225180</td>\n",
       "      <td>0.146954</td>\n",
       "      <td>0.223509</td>\n",
       "      <td>0.223942</td>\n",
       "      <td>6.888317</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▄▁▂▄▄▃▅▅▆▅▆▇▇▇▇█▇▇▇███</td></tr><tr><td>eval/gen_len</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/loss</td><td>█▅▅▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/rouge1</td><td>▁▁▁▄▄▅▅▆▆▆▇▆▇▇▆▇▇▇▇▇██</td></tr><tr><td>eval/rouge2</td><td>▁▂▃▄▅▅▆▆▇▇▇▇▇█▇███████</td></tr><tr><td>eval/rougeL</td><td>▁▁▂▄▄▅▅▆▆▆▇▆▇▇▆▇▇▇▇▇██</td></tr><tr><td>eval/rougeLsum</td><td>▁▁▂▄▄▅▅▆▆▆▇▆▇▇▆▇▇▇▇███</td></tr><tr><td>eval/runtime</td><td>▁▃▁▂▅▆▄▆▅▆▇▆▃█▇▄▆▅▄▃▄▃</td></tr><tr><td>eval/samples_per_second</td><td>█▆█▇▄▃▅▃▄▃▂▃▆▁▂▅▃▄▅▆▅▆</td></tr><tr><td>eval/steps_per_second</td><td>█▆█▇▄▃▅▃▄▃▂▃▆▁▂▅▂▄▅▆▅▆</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▇▂▅█▆▃▃▄▇▂█▇▅▂▃▇▄▁▂▇▃▁</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>6.88832</td></tr><tr><td>eval/gen_len</td><td>128</td></tr><tr><td>eval/loss</td><td>0.41592</td></tr><tr><td>eval/rouge1</td><td>0.22518</td></tr><tr><td>eval/rouge2</td><td>0.14695</td></tr><tr><td>eval/rougeL</td><td>0.22351</td></tr><tr><td>eval/rougeLsum</td><td>0.22394</td></tr><tr><td>eval/runtime</td><td>169.4477</td></tr><tr><td>eval/samples_per_second</td><td>19.457</td></tr><tr><td>eval/steps_per_second</td><td>1.222</td></tr><tr><td>total_flos</td><td>4.816959602688e+16</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>11127</td></tr><tr><td>train/grad_norm</td><td>1.3889</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4191</td></tr><tr><td>train_loss</td><td>0.50095</td></tr><tr><td>train_runtime</td><td>9255.3288</td></tr><tr><td>train_samples_per_second</td><td>9.616</td></tr><tr><td>train_steps_per_second</td><td>1.202</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-monkey-11</strong> at: <a href='https://wandb.ai/skyfurynowonline-yunnan-university/T5-large-on-full-with-rouge-bleu/runs/pufro722' target=\"_blank\">https://wandb.ai/skyfurynowonline-yunnan-university/T5-large-on-full-with-rouge-bleu/runs/pufro722</a><br/> View project at: <a href='https://wandb.ai/skyfurynowonline-yunnan-university/T5-large-on-full-with-rouge-bleu' target=\"_blank\">https://wandb.ai/skyfurynowonline-yunnan-university/T5-large-on-full-with-rouge-bleu</a><br/>Synced 2 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241207_002910-pufro722/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # 定义训练的超参数\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir='./semeval-T5large-with-rouge',  # output directory\n",
    "        save_total_limit=3,       # 只保留最近的 3 个检查点\n",
    "#         report_to=\"wandb\",\n",
    "        num_train_epochs=3,  # total number of training epochs\n",
    "        per_device_train_batch_size=8,  # batch size per device during training\n",
    "        per_device_eval_batch_size=16,  # batch size for evaluation\n",
    "        warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,  # strength of weight decay\n",
    "        logging_dir='./logs',  # directory for storing logs\n",
    "        \n",
    "        # 频繁的日志记录可能导致内存增加，特别是当模型需要频繁评估时。\n",
    "        logging_steps=500,\n",
    "        learning_rate=2e-5,  # Set learning rate\n",
    "        evaluation_strategy=\"steps\",\n",
    "        \n",
    "        eval_accumulation_steps=100,\n",
    "        \n",
    "        # 使用T5-base时遇到loss为NAN的问题，或许尝试不使用gradient_checkpointing\n",
    "        # 尝试禁用gradient_checkpointing和FP16，跑出了结果\n",
    "        \n",
    "        # 过多裁剪会导致不能学习到有用的知识\n",
    "#         max_grad_norm=1.0,  # 最大梯度裁剪，防止梯度爆炸\n",
    "        \n",
    "        save_strategy=\"epoch\",\n",
    "        \n",
    "        gradient_checkpointing=True,\n",
    "#         fp16=True, # 开启混合精度\n",
    "        # gradient_accumulation_steps=8,  # 累积 8 个小批次\n",
    "    )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model = model,\n",
    "        args = training_args,\n",
    "        train_dataset = tokenized_train,\n",
    "        eval_dataset = tokenized_val,\n",
    "#         eval_dataset=tokenized_val_slice,\n",
    "        tokenizer = tokenizer,\n",
    "        data_collator = data_collator,\n",
    "        compute_metrics = compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    wandb.finish()\n",
    "    trainer.save_model(\"./my_model_final-T5large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a067239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, comment vous êtes-vous ?\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./my_model_final-T5large\").to(\"cuda\")\n",
    "tokenizerSelf = AutoTokenizer.from_pretrained(\"./my_model_final-T5large\")\n",
    "text = \"translate English to French: Hello, how are you ? \"\n",
    "inputs = tokenizerSelf(text,return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(inputs['input_ids'],max_length=128,num_beams=5,early_stopping=True)\n",
    "\n",
    "decoded_output = tokenizerSelf.decode(outputs[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48177ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, comment êtes-vous ?\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id).to(\"cuda\")\n",
    "text = \"translate English to French: Hello, how are you ? \"\n",
    "inputs = tokenizer(text,return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(inputs['input_ids'],max_length=128,num_beams=5,early_stopping=True)\n",
    "\n",
    "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd7145-1227-490b-bf52-d5ebeb72e161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
